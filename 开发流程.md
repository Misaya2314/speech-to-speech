# Speech-to-Speech 桌面应用开发文档

## 项目概述

本项目旨在为现有的 Speech-to-Speech 开源模块化解决方案开发一个易于使用的桌面应用程序界面，使普通用户无需技术背景也能使用这一先进的语音对话技术。我们将采用 Electron 框架结合 Vue/React 前端技术栈，并采用完全模块化的设计理念，将前端 UI 和原有语音处理后端作为独立模块开发。

## 技术栈选择

- **前端框架**: Vue.js 3 + TypeScript (或可选择 React)
- **桌面应用框架**: Electron
- **构建工具**: Vite
- **UI 组件库**: Element Plus / Ant Design
- **状态管理**: Pinia
- **打包工具**: electron-builder

## 系统架构

系统采用严格的前后端分离架构，分为两个独立的模块：

1. **前端模块**:

   - Electron 主进程：负责系统层面操作和窗口管理
   - 渲染进程：基于 Vue/React 的用户界面
   - 通信层：负责与后端模块的数据交换

2. **后端模块**:
   - 原有的 S2S 语音处理管道系统
   - WebSocket API：为前端提供标准化的通信接口
   - 音频处理：捕获麦克风输入和处理语音输出

这种分离式设计允许两个模块各自独立开发和测试，最终通过标准化接口集成。

## 功能需求

### 核心功能

1. 语音输入捕获和处理
2. 语音转文本（STT）
3. 文本语言模型处理（LLM）
4. 文本转语音（TTS）
5. 回放生成的语音
6. 本地知识库集成（新增）

### 用户界面功能

1. 开始/停止对话按钮
2. 实时显示识别的文本和模型回复
3. 对话历史记录查看
4. 语音语言切换（支持英文、中文、法语、西班牙语、日语、韩语等）
5. 模型选择和配置界面（STT、LLM、TTS 模型的选择和参数配置）
6. 系统设置（音频设备选择、音量控制等）
7. 导出对话记录
8. 左侧功能导航区（新增）
9. 数据和状态监控区（新增）
10. 本地知识库管理界面（新增）

## 界面设计

根据设计草图和要求，界面将采用工程软件风格的布局，包括以下主要部分：

1. **顶部导航栏**：包含应用标题、菜单选项（文件、模型、显示、语言）、设置按钮等控制选项

2. **左侧功能导航区**：

   - 语义建模（包括语音建模、模型调用）
   - 物理仿真（包括流体分析、结构强度）
   - 知识管理（包括智能索引、规则提取、案例调用、本地知识库）
   - 决策优化（包括方案对比、性能评估、决策生成等）

3. **中央工作区**：

   - 显示对话内容或当前功能的工作视图
   - 提供交互界面

4. **右侧状态区**：

   - Graph 区域：显示模型生成的图表
   - Data 区域：显示数据日志和当前状态信息
   - System Monitor：显示系统资源使用情况

5. **底部输入区**：
   - 麦克风按钮：控制语音输入
   - 文本输入框：允许键入命令
   - 确认按钮：发送文本命令

## 开发路线图

### 第一阶段：模块设计和接口定义（2 周）

1. **前端模块**:

   - 设计 FlowMind 风格 UI 界面和用户交互
   - 定义与后端的通信接口
   - 创建 Electron + Vue/React 项目框架

2. **后端模块**:
   - 在现有 S2S 代码基础上设计 WebSocket API
   - 定义数据交换格式
   - 设计本地知识库接口

### 第二阶段：独立模块开发（4 周）

1. **前端模块**:

   - 开发 UI 组件（工程风格的导航区、工作区、状态区等）
   - 实现音频捕获和播放功能
   - 建立与后端通信的客户端代码
   - 开发本地知识库管理界面

2. **后端模块**:
   - 开发 WebSocket 服务器接口
   - 调整现有语音处理管道以支持前端请求
   - 实现知识库索引和检索功能
   - 实现配置和状态管理功能

### 第三阶段：模块集成和测试（2 周）

1. 集成前端和后端模块
2. 集成本地知识库和 LLM 调用
3. 端到端测试完整流程
4. 优化性能和用户体验

### 第四阶段：打包和部署（1 周）

1. 使用 electron-builder 打包桌面应用
2. 创建安装程序和自动更新机制
3. 用户体验测试和最终优化

## 模块间通信

为了保证前端和后端模块的解耦与独立性，我们采用以下通信机制：

### WebSocket API

作为两个模块之间的主要通信通道，定义标准数据格式：

```
# 前端发送到后端的消息
{
  "type": "start_listening" | "stop_listening" | "set_language" | "set_model" | "set_parameters",
  "data": { ... }  // 取决于消息类型的附加数据
}

# 后端发送到前端的消息
{
  "type": "transcription" | "response" | "audio_chunk" | "status" | "error",
  "data": { ... }  // 取决于消息类型的数据
}
```

### 本地通信（Electron 内部）

```javascript
// 渲染进程到主进程
ipcRenderer.invoke("connect-backend", options);
ipcRenderer.invoke("disconnect-backend");
ipcRenderer.send("audio-data", audioChunk);

// 主进程到渲染进程
ipcMain.on("transcription", (event, text) => {});
ipcMain.on("response", (event, text) => {});
ipcMain.on("audio-response", (event, audioData) => {});
ipcMain.on("status", (event, status) => {});
```

## 项目结构

考虑到模块化设计，项目将被分为两个独立的代码库：

### 1. 前端 UI 项目 (speech-to-speech-ui)

```
speech-to-speech-ui/             # 前端UI项目
├── electron/                    # Electron主进程代码
│   ├── main.js                  # 主进程入口
│   ├── preload.js               # 预加载脚本
│   └── backend-connector.js     # 后端连接模块
├── src/                         # 前端Vue/React代码
│   ├── assets/                  # 静态资源
│   ├── components/              # UI组件
│   │   ├── AppHeader.vue        # 应用头部
│   │   ├── ChatWindow.vue       # 对话窗口
│   │   ├── ControlPanel.vue     # 控制面板
│   │   └── SettingsPanel.vue    # 设置面板
│   ├── views/                   # 页面
│   ├── store/                   # 状态管理
│   ├── utils/                   # 工具函数
│   │   └── websocket-client.js  # WebSocket客户端
│   ├── App.vue                  # 应用主组件
│   └── main.js                  # 渲染进程入口
├── public/                      # 静态文件
├── package.json                 # 项目配置
├── vite.config.ts               # Vite配置
└── tsconfig.json                # TypeScript配置
```

### 2. 现有的后端项目 (speech-to-speech)

```
speech-to-speech/                # 原有项目（现作为后端）
├── TTS/                         # TTS模块
├── STT/                         # STT模块
├── LLM/                         # LLM模块
├── VAD/                         # VAD模块
├── utils/                       # 工具函数
├── connections/                 # 连接模块
├── arguments_classes/           # 参数类
├── python/                      # 新增的API模块
│   ├── api/                     # API接口
│   │   └── websocket_server.py  # WebSocket服务器
│   └── requirements.txt         # Python依赖
├── s2s_pipeline.py              # 语音处理管道
├── listen_and_play.py           # 音频捕获和播放模块
└── requirements.txt             # 项目依赖
```

## 开发步骤

### 后端模块（基于现有项目）

1. **添加 WebSocket 服务器**:

   ```python
   # 在 python/api/websocket_server.py 中实现
   import asyncio
   import websockets
   import json
   from queue import Queue

   class S2SWebSocketServer:
       # 实现 WebSocket 服务器接口...
   ```

2. **调整 S2S 管道以接受远程命令**:
   ```python
   # 修改 s2s_pipeline.py 添加 API 模式
   # 使用命令行参数 --api_mode websocket 启动
   ```

### 前端模块（新建项目）

1. **创建 Electron + Vue 项目**:

   ```bash
   # 初始化项目
   npm init -y
   npm install electron vue vite @vitejs/plugin-vue
   ```

2. **实现 WebSocket 客户端**:

   ```javascript
   // 在 src/utils/websocket-client.js 中实现
   class S2SWebSocketClient {
     // 实现 WebSocket 客户端...
   }
   ```

3. **开发 UI 组件**:
   ```javascript
   // 实现各种 UI 组件和页面
   ```

## 打包和发布

### 独立打包模式

在独立打包模式下，前端和后端作为独立应用，用户需要分别启动：

1. **后端打包**:

   ```bash
   # 使用 PyInstaller 打包
   pyinstaller --onefile --noconsole --hidden-import=torch python/api/websocket_server.py
   ```

2. **前端打包**:
   ```bash
   # 使用 electron-builder 打包
   npm run build
   npm run electron:build
   ```

### 集成打包模式

在集成打包模式下，后端作为前端的资源被打包到一起：

1. **集成打包**:
   ```javascript
   // package.json 配置
   "build": {
     "appId": "com.speechtospeech.app",
     "productName": "Speech To Speech",
     "files": [
       "dist/**/*",
       "electron/**/*",
       "python_backend/**/*"  // 包含打包后的后端
     ],
     "extraResources": [
       {
         "from": "path/to/backend/executable",
         "to": "."
       }
     ]
   }
   ```

## 测试计划

为确保模块间无缝集成，测试分为三个层次：

1. **单元测试**：测试各个组件和函数
2. **模块测试**：分别测试前端和后端模块功能
3. **集成测试**：测试前后端模块间的通信和协作

## 开发环境设置

### 前端环境

1. 安装 Node.js (v16+)和 npm
2. 克隆前端项目
3. 运行 `npm install` 安装依赖
4. 运行 `npm run dev` 启动开发服务器

### 后端环境

1. 安装 Python 3.9+
2. 克隆后端项目
3. 运行 `pip install -r requirements.txt` 安装依赖
4. 运行 `python python/api/websocket_server.py` 启动 API 服务器

## 新增功能：本地知识库

### 功能概述

本地知识库功能允许用户上传和索引本地文档（如 PDF、DOC、TXT 等），使模型在回答问题时能够参考这些文档中的信息。

### 实现方案

1. **文档处理层**:

   - 实现文档解析器，支持多种文档格式
   - 实现文本分块（chunking）
   - 生成文本向量表示（embeddings）

2. **索引层**:

   - 创建向量数据库
   - 实现相似度搜索
   - 缓存机制

3. **检索层**:

   - 实现相关度判断
   - 检索优化
   - 上下文组装

4. **集成层**:
   - 将检索结果与 LLM 提示集成
   - 处理引用和来源标记

### API 设计

新增 WebSocket 消息类型：

```
# 本地知识库相关消息
{
  "type": "upload_document",
  "data": {
    "document_name": "文档名称",
    "document_type": "pdf/doc/txt",
    "document_content": "Base64编码的文档内容"
  }
}

{
  "type": "build_index",
  "data": {}
}

{
  "type": "search_knowledge",
  "data": {
    "query": "搜索查询",
    "top_k": 3
  }
}
```

### 前端组件

1. **知识库管理界面**:

   - 文档上传组件
   - 索引构建和管理
   - 文档列表和状态

2. **设置面板扩展**:

   - 启用/禁用本地知识库
   - 相关度阈值设置
   - 最大检索文档数设置

3. **对话界面扩展**:
   - 显示引用来源
   - 引用标记和高亮

## 结论

通过这种模块化设计，我们可以确保前端 UI 和后端语音处理系统的完全解耦，各自可以独立开发、测试和部署。这种架构提供了更好的可维护性和可扩展性，同时为用户提供了直观易用的桌面应用界面，使 Speech-to-Speech 技术更加普及。

前端 UI 项目专注于用户体验和界面交互，通过标准化的 WebSocket API 与后端通信；而后端项目则专注于核心的语音处理功能，保持其作为独立服务的灵活性。这种分离也使得未来可以更容易地开发不同的客户端（如移动应用）来连接同一个后端服务。
